{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0068f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm\n",
    "from fnn import FNN\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b30ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data used to train / evaluate the router\n",
    "\n",
    "python = pd.read_csv('data/python.csv')\n",
    "\n",
    "medical = pd.read_csv('data/medical.csv')\n",
    "\n",
    "education = pd.read_parquet(\"hf://datasets/kaitchup/qa-chat-persona-education/data/train-00000-of-00001.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05bb020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create both questions and the labels for the router \n",
    "\n",
    "texts = list(python['Question'])\n",
    "\n",
    "labels = [0] * len(python)\n",
    "\n",
    "labels.extend([1] * len(medical))\n",
    "\n",
    "texts.extend(list(medical['question']))\n",
    "\n",
    "texts.extend(list(education['question']))\n",
    "\n",
    "labels.extend([2] * len(education))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58fbf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the the texts into bag of words\n",
    "vectorizer = CountVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(texts).toarray()\n",
    "y = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e14c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/qzh6jlhn6lj_qvnz51z6sf2h0000gn/T/ipykernel_73637/2925166974.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.labels = torch.tensor(labels, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "# create dataset used for torch data loader\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "train_dataset = TextDataset(X_train, y_train)\n",
    "test_dataset = TextDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88209267",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "model = FNN(input_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a289e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(logits, labels):\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "    correct = (predictions == labels).sum().item()\n",
    "    return correct / labels.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4a8763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 8118/8118 [00:07<00:00, 1067.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.0164, Accuracy: 0.9943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 8118/8118 [00:08<00:00, 926.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Loss: 0.0028, Accuracy: 0.9992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 8118/8118 [00:09<00:00, 875.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Loss: 0.0012, Accuracy: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 8118/8118 [00:08<00:00, 1010.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Loss: 0.0017, Accuracy: 0.9995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 8118/8118 [00:06<00:00, 1280.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Loss: 0.0005, Accuracy: 0.9998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train the router for num_epochs \n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    for batch_data, batch_labels in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_data)\n",
    "\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * batch_data.size(0)\n",
    "        epoch_acc += compute_accuracy(outputs, batch_labels) * batch_data.size(0)\n",
    "\n",
    "    epoch_loss /= len(train_loader.dataset)\n",
    "    epoch_acc /= len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac0f5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.91%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the router on the held out test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_data, batch_labels in test_loader:\n",
    "        outputs = model(batch_data)\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "        total += batch_labels.size(0)\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0b7e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer has been saved to 'count_vectorizer.joblib'.\n"
     ]
    }
   ],
   "source": [
    "# Save both the router and the bag of words vectorizer\n",
    "\n",
    "torch.save(model.state_dict(), 'router.safetensors')\n",
    "\n",
    "joblib.dump(vectorizer, 'count_vectorizer.joblib')\n",
    "print(\"Vectorizer has been saved to 'count_vectorizer.joblib'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
